{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing past buoy data and reanalyses for use in model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Concatenate all past buoy data into a single dataframe\n",
    "This section will collect all of the cleaned buoy data and combine them into a single dataframe. A column to represent the day of year (DOY) as an integer is also added. These data will be used (along with weather reanalyses) as training data for the machine learning model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate multiple raw buoy CSV files into a single DataFrame and add a new column with the Day of Year (DOY) as an integer\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Define the path to the folder containing the CSV files\n",
    "folder_path = '../data/cleaned/buoydata/past'\n",
    "\n",
    "# Use glob to get all CSV files in the folder\n",
    "csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through the list of CSV files and read each one into a DataFrame\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Rename the lat and lon columns to Latitude and Longitude\n",
    "combined_df.rename(columns={'Lat': 'Latitude', 'Lon': 'Longitude'}, inplace=True)\n",
    "\n",
    "# Pad Month, Day, Hour, Min, and Sec columns with leading zeros\n",
    "combined_df['Month'] = combined_df['Month'].apply(lambda x: f'{x:02}')\n",
    "combined_df['Day'] = combined_df['Day'].apply(lambda x: f'{x:02}')\n",
    "combined_df['Hour'] = combined_df['Hour'].apply(lambda x: f'{x:02}')\n",
    "combined_df['Min'] = combined_df['Min'].apply(lambda x: f'{x:02}')\n",
    "combined_df['Sec'] = combined_df['Sec'].apply(lambda x: f'{x:02}')\n",
    "\n",
    "# Create a new column called datetime by combining Year, Month, Day, Hour, Min, and Sec columns\n",
    "combined_df['datetime'] = pd.to_datetime(combined_df['Year'].astype(str) + '-' +\n",
    "                                         combined_df['Month'].astype(str) + '-' +\n",
    "                                         combined_df['Day'].astype(str) + ' ' +\n",
    "                                         combined_df['Hour'].astype(str) + ':' +\n",
    "                                         combined_df['Min'].astype(str) + ':' +\n",
    "                                         combined_df['Sec'].astype(str))\n",
    "\n",
    "# Add a new column with the Day of Year (DOY) as an integer\n",
    "combined_df['DOY'] = combined_df['datetime'].dt.dayofyear\n",
    "\n",
    "# Display the combined DataFrame\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cleaned buoy data geospatial bounds confirmation\n",
    "To confirm the resulting dataframe only contains buoy data within the area of interest (Arctic Ocean), this cell will analyze and display the minimum and maximum values of the latitude and longitude fields of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the latitude and longitude ranges\n",
    "\n",
    "min_latitude = combined_df['Latitude'].min()\n",
    "max_latitude = combined_df['Latitude'].max()\n",
    "min_longitude = combined_df['Longitude'].min()\n",
    "max_longitude = combined_df['Longitude'].max()\n",
    "\n",
    "print(f\"Latitude: min = {min_latitude}, max = {max_latitude}\")\n",
    "print(f\"Longitude: min = {min_longitude}, max = {max_longitude}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the data to only include rows where the month is January\n",
    "combined_df = combined_df[combined_df['Month'] == '01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing current buoy data and forecasts for use in model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Concatenate all current buoy data into a single dataframe\n",
    "This section will collect all of the cleaned buoy data and combine them into a single dataframe. A column to represent the day of year (DOY) as an integer is also added. Finally, the buoy data is subsetted to only the most recent positions for each buoyID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate multiple current buoy CSV files into a single DataFrame and add a new column with the Day of Year (DOY) as an integer\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Define the path to the folder containing the CSV files\n",
    "folder_path = '../data/cleaned/buoydata/current'\n",
    "\n",
    "# Use glob to get all CSV files in the folder\n",
    "csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through the list of CSV files and read each one into a DataFrame\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df_current = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Make a new column in the dataframe of DOY truncated to an integer\n",
    "combined_df_current['DOY_int'] = combined_df_current['DOY'].astype(int)\n",
    "\n",
    "# Rename the lat and lon columns to Latitude and Longitude\n",
    "combined_df_current.rename(columns={'Lat': 'Latitude', 'Lon': 'Longitude'}, inplace=True)\n",
    "\n",
    "# For each unique BuoyID, keep only the most current position based on the DOY column\n",
    "combined_df_current = combined_df_current.loc[combined_df_current.groupby('BuoyID')['DOY'].idxmax()]\n",
    "\n",
    "# Display the combined DataFrame\n",
    "combined_df_current.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Converting the netCDF GFS forecast data into arrays for interpolation with current buoy positions for use as initial conditions for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell converts the GFS netCDF file into arrays for the `ugrd` and `vgrd` variables at a specific pressure level (currently set to the second item in the list, which corresponds to near-surface conditions). The script ensures that there is exactly one file in the specified directory and extracts the necessary variables from the netCDF dataset. The shapes of the resulting arrays are printed to verify the extraction process. This step is crucial for preparing the forecast data for interpolation with the current buoy positions, which will be used as initial conditions for prediction models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the GFS netCDF file into arrays for the ugrd and vgrd variables at a specific pressure level (currently set to the second item in the list \n",
    "# which corresponds to near surface conditions)\n",
    "\n",
    "import netCDF4 as nc\n",
    "import os\n",
    "\n",
    "# Define the directory path to the dataset in the data/raw/forecasts/gfs folder\n",
    "directory_path = '../data/raw/forecasts/gfs'\n",
    "\n",
    "# Get the list of files in the directory\n",
    "files = os.listdir(directory_path)\n",
    "\n",
    "# Ensure there is exactly one file in the directory\n",
    "if len(files) != 1:\n",
    "    raise ValueError(\"There should be exactly one file in the directory.\")\n",
    "\n",
    "# Get the file path\n",
    "file_path = os.path.join(directory_path, files[0])\n",
    "\n",
    "# Reopen the dataset\n",
    "dataset = nc.Dataset(file_path, 'r')\n",
    "\n",
    "# Extract the second item in the pfull list\n",
    "pfull_index = 1\n",
    "\n",
    "# Create arrays for ugrd and vgrd with pfull set to the second item\n",
    "ugrd_array = dataset.variables['ugrd'][0, pfull_index, :, :]\n",
    "vgrd_array = dataset.variables['vgrd'][0, pfull_index, :, :]\n",
    "\n",
    "# Print the shapes of the arrays to verify\n",
    "print(\"ugrd_array shape:\", ugrd_array.shape)\n",
    "print(\"vgrd_array shape:\", vgrd_array.shape)\n",
    "\n",
    "# Extract the latitude and longitude variables from the dataset\n",
    "lat_array = dataset.variables['lat'][:]\n",
    "lon_array = dataset.variables['lon'][:]\n",
    "\n",
    "# Print the shapes of the latitude and longitude arrays to verify\n",
    "print(\"lat_array shape:\", lat_array.shape)\n",
    "print(\"lon_array shape:\", lon_array.shape)\n",
    "\n",
    "# Close the dataset\n",
    "dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interpolating forecast data with current buoy positions\n",
    "This cell will use the GFS forecasts to assign wind forecast values to the current buoy positions for use as initial conditions for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "# Step 1: Get the buoy points from combined_df_current\n",
    "buoy_points = combined_df_current[['Latitude', 'Longitude']].values\n",
    "\n",
    "# Step 2: Create a meshgrid of the lat and lon arrays\n",
    "lon_grid, lat_grid = np.meshgrid(lon_array[0], lat_array[:, 0])\n",
    "\n",
    "# Step 3: Flatten the meshgrid arrays for interpolation\n",
    "points = np.array([lat_grid.flatten(), lon_grid.flatten()]).T\n",
    "\n",
    "# Step 4: Interpolate the ugrd and vgrd values\n",
    "ugrd_values = ugrd_array.flatten()\n",
    "vgrd_values = vgrd_array.flatten()\n",
    "\n",
    "interpolated_ugrd = griddata(points, ugrd_values, buoy_points, method='linear')\n",
    "interpolated_vgrd = griddata(points, vgrd_values, buoy_points, method='linear')\n",
    "\n",
    "# Step 5: Assign the interpolated values to the DataFrame\n",
    "combined_df_current['ugrd_gfs_interp'] = interpolated_ugrd\n",
    "combined_df_current['vgrd_gfs_interp'] = interpolated_vgrd\n",
    "\n",
    "# Step 6: Assign the discrete values (closest grid point) to the DataFrame\n",
    "assigned_ugrd = []\n",
    "assigned_vgrd = []\n",
    "\n",
    "for lat, lon in buoy_points:\n",
    "    lat_idx = (np.abs(lat_array[:, 0] - lat)).argmin()\n",
    "    lon_idx = (np.abs(lon_array[0] - lon)).argmin()\n",
    "    \n",
    "    assigned_ugrd.append(ugrd_array[lat_idx, lon_idx])\n",
    "    assigned_vgrd.append(vgrd_array[lat_idx, lon_idx])\n",
    "\n",
    "combined_df_current['ugrd_gfs_discrete'] = assigned_ugrd\n",
    "combined_df_current['vgrd_gfs_discrete'] = assigned_vgrd\n",
    "\n",
    "# Ensure the new columns are of float type\n",
    "combined_df_current['ugrd_gfs_interp'] = combined_df_current['ugrd_gfs_interp'].astype(float)\n",
    "combined_df_current['vgrd_gfs_interp'] = combined_df_current['vgrd_gfs_interp'].astype(float)\n",
    "combined_df_current['ugrd_gfs_discrete'] = combined_df_current['ugrd_gfs_discrete'].astype(float)\n",
    "combined_df_current['vgrd_gfs_discrete'] = combined_df_current['vgrd_gfs_discrete'].astype(float)\n",
    "\n",
    "# Display the updated DataFrame head\n",
    "combined_df_current.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
