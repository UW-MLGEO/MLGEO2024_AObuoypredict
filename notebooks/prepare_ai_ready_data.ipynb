{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing past buoy data and reanalyses for use in model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Concatenate all past buoy data into a single dataframe\n",
    "This section will collect all of the cleaned buoy data and combine them into a single dataframe. A column to represent the day of year (DOY) as an integer is also added. These data will be used (along with weather reanalyses) as training data for the machine learning model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BuoyID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Min</th>\n",
       "      <th>Sec</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>GPSdelay</th>\n",
       "      <th>BPT</th>\n",
       "      <th>BP</th>\n",
       "      <th>Ts</th>\n",
       "      <th>Ta</th>\n",
       "      <th>Th</th>\n",
       "      <th>Batt</th>\n",
       "      <th>datetime</th>\n",
       "      <th>DOY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300025010734900</td>\n",
       "      <td>2023</td>\n",
       "      <td>08</td>\n",
       "      <td>07</td>\n",
       "      <td>00</td>\n",
       "      <td>07</td>\n",
       "      <td>32</td>\n",
       "      <td>77.33740</td>\n",
       "      <td>-138.15785</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1016.5</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>12.96</td>\n",
       "      <td>13</td>\n",
       "      <td>2023-08-07 00:07:32</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300025010734900</td>\n",
       "      <td>2023</td>\n",
       "      <td>08</td>\n",
       "      <td>07</td>\n",
       "      <td>00</td>\n",
       "      <td>51</td>\n",
       "      <td>05</td>\n",
       "      <td>77.33538</td>\n",
       "      <td>-138.13705</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1016.5</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>13.86</td>\n",
       "      <td>13</td>\n",
       "      <td>2023-08-07 00:51:05</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300025010734900</td>\n",
       "      <td>2023</td>\n",
       "      <td>08</td>\n",
       "      <td>07</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>40</td>\n",
       "      <td>77.33479</td>\n",
       "      <td>-138.13317</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1016.6</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>13.90</td>\n",
       "      <td>13</td>\n",
       "      <td>2023-08-07 01:01:40</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300025010734900</td>\n",
       "      <td>2023</td>\n",
       "      <td>08</td>\n",
       "      <td>07</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>21</td>\n",
       "      <td>77.33148</td>\n",
       "      <td>-138.11950</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>12.74</td>\n",
       "      <td>13</td>\n",
       "      <td>2023-08-07 02:01:21</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300025010734900</td>\n",
       "      <td>2023</td>\n",
       "      <td>08</td>\n",
       "      <td>07</td>\n",
       "      <td>03</td>\n",
       "      <td>01</td>\n",
       "      <td>11</td>\n",
       "      <td>77.32867</td>\n",
       "      <td>-138.12018</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1017.4</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>11.92</td>\n",
       "      <td>13</td>\n",
       "      <td>2023-08-07 03:01:11</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            BuoyID  Year Month Day Hour Min Sec  Latitude  Longitude  \\\n",
       "0  300025010734900  2023    08  07   00  07  32  77.33740 -138.15785   \n",
       "1  300025010734900  2023    08  07   00  51  05  77.33538 -138.13705   \n",
       "2  300025010734900  2023    08  07   01  01  40  77.33479 -138.13317   \n",
       "3  300025010734900  2023    08  07   02  01  21  77.33148 -138.11950   \n",
       "4  300025010734900  2023    08  07   03  01  11  77.32867 -138.12018   \n",
       "\n",
       "   GPSdelay    BPT      BP     Ts     Ta     Th  Batt            datetime  DOY  \n",
       "0         0 -999.0  1016.5 -999.0 -999.0  12.96    13 2023-08-07 00:07:32  219  \n",
       "1         0 -999.0  1016.5 -999.0 -999.0  13.86    13 2023-08-07 00:51:05  219  \n",
       "2         0 -999.0  1016.6 -999.0 -999.0  13.90    13 2023-08-07 01:01:40  219  \n",
       "3         0 -999.0  -999.0 -999.0 -999.0  12.74    13 2023-08-07 02:01:21  219  \n",
       "4         0 -999.0  1017.4 -999.0 -999.0  11.92    13 2023-08-07 03:01:11  219  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate multiple raw buoy CSV files into a single DataFrame and add a new column with the Day of Year (DOY) as an integer\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Define the path to the folder containing the CSV files\n",
    "folder_path = '../data/cleaned/buoydata/past'\n",
    "\n",
    "# Use glob to get all CSV files in the folder\n",
    "csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through the list of CSV files and read each one into a DataFrame\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Rename the lat and lon columns to Latitude and Longitude\n",
    "combined_df.rename(columns={'Lat': 'Latitude', 'Lon': 'Longitude'}, inplace=True)\n",
    "\n",
    "# Pad Month, Day, Hour, Min, and Sec columns with leading zeros\n",
    "combined_df['Month'] = combined_df['Month'].apply(lambda x: f'{x:02}')\n",
    "combined_df['Day'] = combined_df['Day'].apply(lambda x: f'{x:02}')\n",
    "combined_df['Hour'] = combined_df['Hour'].apply(lambda x: f'{x:02}')\n",
    "combined_df['Min'] = combined_df['Min'].apply(lambda x: f'{x:02}')\n",
    "combined_df['Sec'] = combined_df['Sec'].apply(lambda x: f'{x:02}')\n",
    "\n",
    "# Create a new column called datetime by combining Year, Month, Day, Hour, Min, and Sec columns\n",
    "combined_df['datetime'] = pd.to_datetime(combined_df['Year'].astype(str) + '-' +\n",
    "                                         combined_df['Month'].astype(str) + '-' +\n",
    "                                         combined_df['Day'].astype(str) + ' ' +\n",
    "                                         combined_df['Hour'].astype(str) + ':' +\n",
    "                                         combined_df['Min'].astype(str) + ':' +\n",
    "                                         combined_df['Sec'].astype(str))\n",
    "\n",
    "# Add a new column with the Day of Year (DOY) as an integer\n",
    "combined_df['DOY'] = combined_df['datetime'].dt.dayofyear\n",
    "\n",
    "# Display the combined DataFrame\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cleaned buoy data geospatial bounds confirmation\n",
    "This cell will analyze and display the minimum and maximum values of the latitude and longitude fields of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latitude: min = 23.863, max = 89.9932\n",
      "Longitude: min = -179.99977, max = 180.0\n"
     ]
    }
   ],
   "source": [
    "# Confirm the latitude and longitude ranges\n",
    "\n",
    "min_latitude = combined_df['Latitude'].min()\n",
    "max_latitude = combined_df['Latitude'].max()\n",
    "min_longitude = combined_df['Longitude'].min()\n",
    "max_longitude = combined_df['Longitude'].max()\n",
    "\n",
    "print(f\"Latitude: min = {min_latitude}, max = {max_latitude}\")\n",
    "print(f\"Longitude: min = {min_longitude}, max = {max_longitude}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interpolate ERA5 reanalysis data to past buoy locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uwnd_array shape: (8760, 269, 1440)\n",
      "vwnd_array shape: (8760, 269, 1440)\n",
      "            BuoyID  Year Month Day Hour Min Sec  Latitude  Longitude  \\\n",
      "0  300025010734900  2023    08  07   00  07  32  77.33740 -138.15785   \n",
      "1  300025010734900  2023    08  07   00  51  05  77.33538 -138.13705   \n",
      "2  300025010734900  2023    08  07   01  01  40  77.33479 -138.13317   \n",
      "3  300025010734900  2023    08  07   02  01  21  77.33148 -138.11950   \n",
      "4  300025010734900  2023    08  07   03  01  11  77.32867 -138.12018   \n",
      "\n",
      "   GPSdelay    BPT      BP     Ts     Ta     Th  Batt            datetime  \\\n",
      "0         0 -999.0  1016.5 -999.0 -999.0  12.96    13 2023-08-07 00:07:32   \n",
      "1         0 -999.0  1016.5 -999.0 -999.0  13.86    13 2023-08-07 00:51:05   \n",
      "2         0 -999.0  1016.6 -999.0 -999.0  13.90    13 2023-08-07 01:01:40   \n",
      "3         0 -999.0  -999.0 -999.0 -999.0  12.74    13 2023-08-07 02:01:21   \n",
      "4         0 -999.0  1017.4 -999.0 -999.0  11.92    13 2023-08-07 03:01:11   \n",
      "\n",
      "   DOY  era5_uwnd  era5_vwnd  \n",
      "0  219  -6.943024   4.360657  \n",
      "1  219  -7.594177   4.592392  \n",
      "2  219  -7.594177   4.592392  \n",
      "3  219  -6.301437   3.599380  \n",
      "4  219  -3.661819   1.544037  \n",
      "The script has completed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "from scipy.spatial import cKDTree\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# Load the NetCDF files\n",
    "uwnd_nc_file_path = '../data/raw/reanalyses/ERA5/era5_uwnd_2023.nc'\n",
    "vwnd_nc_file_path = '../data/raw/reanalyses/ERA5/era5_vwnd_2023.nc'\n",
    "uwnd_ds = nc.Dataset(uwnd_nc_file_path)\n",
    "vwnd_ds = nc.Dataset(vwnd_nc_file_path)\n",
    "\n",
    "# Extract the valid_time, latitudes, longitudes, and u-component wind values from the NetCDF file\n",
    "valid_time = uwnd_ds.variables['valid_time'][:]  # Assuming 'valid_time' is the variable name for time\n",
    "latitudes = uwnd_ds.variables['latitude'][:]\n",
    "longitudes = uwnd_ds.variables['longitude'][:]\n",
    "uwnd_array = uwnd_ds.variables['u'][:, 0, :, :]  # Assuming 'u' is the variable name for u-component wind and removing the pressure dimension\n",
    "vwnd_array = vwnd_ds.variables['v'][:, 0, :, :]  # Assuming 'v' is the variable name for v-component wind and removing the pressure dimension\n",
    "\n",
    "# Add a column to the dataframe called \"timestamp\"\n",
    "combined_df['timestamp'] = combined_df['datetime'].apply(lambda x: int(x.replace(tzinfo=timezone.utc).timestamp()))\n",
    "\n",
    "# Create a KDTree for fast spatial lookup\n",
    "lat_lon_pairs = np.array([(lat, lon) for lat in latitudes for lon in longitudes])\n",
    "tree = cKDTree(lat_lon_pairs)\n",
    "\n",
    "# Add new columns to combined_df for the u-component and v-component wind values\n",
    "combined_df['era5_uwnd'] = np.nan\n",
    "combined_df['era5_vwnd'] = np.nan\n",
    "\n",
    "# Check the shape of the uwnd_array\n",
    "print(f\"uwnd_array shape: {uwnd_array.shape}\")\n",
    "print(f\"vwnd_array shape: {vwnd_array.shape}\")\n",
    "\n",
    "# Iterate through each row in the dataframe\n",
    "for index, row in combined_df.iterrows():\n",
    "    # Find the value of the netCDF variable valid_time closest to the timestamp value\n",
    "    timestamp = row['timestamp']\n",
    "    time_diffs = np.abs(valid_time - timestamp)\n",
    "    closest_time_index = np.argmin(time_diffs)\n",
    "    \n",
    "    # Check if the calculated index is within the bounds of the uwnd_array\n",
    "    if closest_time_index < 0 or closest_time_index >= uwnd_array.shape[0]:\n",
    "        print(f\"Skipping row {index} with timestamp {timestamp} as it is out of bounds\")\n",
    "        continue\n",
    "    \n",
    "    # Select the corresponding netCDF slices\n",
    "    uwnd_slice = uwnd_array[closest_time_index, :, :]\n",
    "    vwnd_slice = vwnd_array[closest_time_index, :, :]\n",
    "    \n",
    "    # Find the grid cell of the netCDF slice closest to the Latitude and Longitude position\n",
    "    lat_lon = (row['Latitude'], row['Longitude'])\n",
    "    _, closest_point_index = tree.query(lat_lon)\n",
    "    closest_lat, closest_lon = lat_lon_pairs[closest_point_index]\n",
    "    \n",
    "    # Find the index of the closest latitude/longitude pair in the arrays\n",
    "    lat_index = np.where(latitudes == closest_lat)[0][0]\n",
    "    lon_index = np.where(longitudes == closest_lon)[0][0]\n",
    "    \n",
    "    # Assign the corresponding u and v values to the new columns in the dataframe\n",
    "    combined_df.at[index, 'era5_uwnd'] = uwnd_slice[lat_index, lon_index]\n",
    "    combined_df.at[index, 'era5_vwnd'] = vwnd_slice[lat_index, lon_index]\n",
    "\n",
    "# Drop the timestamp column from the dataframe\n",
    "combined_df.drop(columns=['timestamp'], inplace=True)\n",
    "\n",
    "# Print the dataframe head\n",
    "print(combined_df.head())\n",
    "\n",
    "# Print a message saying the script has completed\n",
    "print(\"The script has completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
