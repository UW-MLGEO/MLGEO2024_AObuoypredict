{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing past buoy data and reanalyses for use in model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Concatenate all past buoy data into a single dataframe\n",
    "This section will collect all of the cleaned buoy data and combine them into a single dataframe. A column to represent the day of year (DOY) as an integer is also added. These data will be used (along with weather reanalyses) as training data for the machine learning model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate multiple raw buoy CSV files into a single DataFrame and add a new column with the Day of Year (DOY) as an integer\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Define the path to the folder containing the CSV files\n",
    "folder_path = '../data/cleaned/buoydata/past'\n",
    "\n",
    "# Use glob to get all CSV files in the folder\n",
    "csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through the list of CSV files and read each one into a DataFrame\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Make a new column in the dataframe of DOY truncated to an integer\n",
    "combined_df['DOY_int'] = combined_df['DOY'].astype(int)\n",
    "\n",
    "# Rename the lat and lon columns to Latitude and Longitude\n",
    "combined_df.rename(columns={'Lat': 'Latitude', 'Lon': 'Longitude'}, inplace=True)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cleaned buoy data geospatial bounds confirmation\n",
    "To confirm the resulting dataframe only contains buoy data within the area of interest (Arctic Ocean), this cell will analyze and display the minimum and maximum values of the latitude and longitude fields of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the latitude and longitude ranges\n",
    "\n",
    "min_latitude = combined_df['Latitude'].min()\n",
    "max_latitude = combined_df['Latitude'].max()\n",
    "min_longitude = combined_df['Longitude'].min()\n",
    "max_longitude = combined_df['Longitude'].max()\n",
    "\n",
    "print(f\"Latitude: min = {min_latitude}, max = {max_latitude}\")\n",
    "print(f\"Longitude: min = {min_longitude}, max = {max_longitude}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convert the NCEP reanalysis data from netCDF to numpy arrays\n",
    "This cell will convert the NCEP reanalysis data from netCDF to 3-dimensional numpy arrays and convert the time dimension into a day of year (DOY) value. This will facilitate interpolation with the buoy data. The script will print the bounds of the geospatial elements of the arrays to confirm they match with the bounds of the buoy data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the uwnd and vwnd NetCDF files to 3D numpy arrays and convert the time variable as day of year (DOY)\n",
    "\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# Open the NetCDF file\n",
    "file_path = '..\\\\data\\\\raw\\\\reanalyses\\\\ncep\\\\uwnd.sfc.2024.nc'\n",
    "dataset = nc.Dataset(file_path, 'r')\n",
    "\n",
    "# Extract the uwnd variable\n",
    "uwnd_var = dataset.variables['uwnd']\n",
    "\n",
    "# Convert the uwnd variable to a 3D numpy array\n",
    "uwnd_3d_array = uwnd_var[:]\n",
    "\n",
    "# Open the vwnd NetCDF file\n",
    "vwnd_file_path = '..\\\\data\\\\raw\\\\reanalyses\\\\ncep\\\\vwnd.sfc.2024.nc'\n",
    "vwnd_dataset = nc.Dataset(vwnd_file_path, 'r')\n",
    "\n",
    "# Extract the vwnd variable\n",
    "vwnd_var = vwnd_dataset.variables['vwnd']\n",
    "\n",
    "# Convert the vwnd variable to a 3D numpy array\n",
    "vwnd_3d_array = vwnd_var[:]\n",
    "\n",
    "# Extract the latitudes and longitudes\n",
    "latitudes = vwnd_dataset.variables['lat'][:]\n",
    "longitudes = vwnd_dataset.variables['lon'][:]\n",
    "\n",
    "# Convert the time variable to day of year (DOY)\n",
    "time_var = vwnd_dataset.variables['time']\n",
    "reference_date_str = time_var.units.split('since')[1].strip().split('.')[0]\n",
    "reference_date = datetime.datetime.strptime(reference_date_str, '%Y-%m-%d %H:%M:%S')\n",
    "doy = [(reference_date + datetime.timedelta(days=t)).timetuple().tm_yday for t in time_var[:]]\n",
    "\n",
    "# Ensure the DOY values are within the valid range\n",
    "doy = np.array(doy)\n",
    "valid_indices = (doy >= 1) & (doy <= 365)\n",
    "doy = doy[valid_indices]\n",
    "uwnd_3d_array = uwnd_3d_array[valid_indices]\n",
    "vwnd_3d_array = vwnd_3d_array[valid_indices]\n",
    "\n",
    "# Print the shape of the uwnd and vwnd arrays\n",
    "print(uwnd_3d_array.shape)\n",
    "print(vwnd_3d_array.shape)\n",
    "\n",
    "# Close the NetCDF files\n",
    "dataset.close()\n",
    "vwnd_dataset.close()\n",
    "\n",
    "# Print the minimum and maximum values of the lat and lon in each array\n",
    "print(f\"uwnd_3d_array lat min: {latitudes.min()}, lat max: {latitudes.max()}\")\n",
    "print(f\"uwnd_3d_array lon min: {longitudes.min()}, lon max: {longitudes.max()}\")\n",
    "\n",
    "print(f\"vwnd_3d_array lat min: {latitudes.min()}, lat max: {latitudes.max()}\")\n",
    "print(f\"vwnd_3d_array lon min: {longitudes.min()}, lon max: {longitudes.max()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Assign NCEP reanalysis to buoy data (interpolation and discrete values)\n",
    "This section will assign the u-component and v-component (uwnd and vwnd) of the NCEP reanalysis to the past buoy data, with steps taken to ensure that the data from the correct day of year is assigned to the buoy data. Both interpolation and discrete value assignment are used and stored in separate columns for more options in model training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the interpolated uwnd and vwnd values to the combined DataFrame\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "# Assuming combined_df, uwnd_3d_array, vwnd_3d_array, latitudes, and longitudes are already defined\n",
    "\n",
    "# Step 1: Get a list of the unique DOY_int values in the data frame\n",
    "unique_doy = combined_df['DOY_int'].unique()\n",
    "\n",
    "# Step 2: Iterate through each unique value\n",
    "for doy in unique_doy:\n",
    "    # Step 3: Select the corresponding layers of the 3D arrays for the same DOY\n",
    "    uwnd_layer = uwnd_3d_array[doy - 1]  # Assuming DOY starts from 1\n",
    "    vwnd_layer = vwnd_3d_array[doy - 1]  # Assuming DOY starts from 1\n",
    "    \n",
    "    # Get the buoy data for the current DOY\n",
    "    buoy_data = combined_df[combined_df['DOY_int'] == doy]\n",
    "    \n",
    "    # Step 4: Interpolate the buoy data with the corresponding uwnd and vwnd values\n",
    "    points = np.array([(lat, lon) for lat in latitudes for lon in longitudes])\n",
    "    uwnd_values = uwnd_layer.flatten()\n",
    "    vwnd_values = vwnd_layer.flatten()\n",
    "    \n",
    "    buoy_points = buoy_data[['Latitude', 'Longitude']].values\n",
    "    interpolated_uwnd = griddata(points, uwnd_values, buoy_points, method='linear')\n",
    "    interpolated_vwnd = griddata(points, vwnd_values, buoy_points, method='linear')\n",
    "    \n",
    "    # Step 5: Append the results as new columns in the dataframe\n",
    "    combined_df.loc[combined_df['DOY_int'] == doy, 'uwnd_ncep_interp'] = interpolated_uwnd\n",
    "    combined_df.loc[combined_df['DOY_int'] == doy, 'vwnd_ncep_interp'] = interpolated_vwnd\n",
    "\n",
    "# Ensure the new columns are of float type\n",
    "combined_df['uwnd_ncep_interp'] = combined_df['uwnd_ncep_interp'].astype(float)\n",
    "combined_df['vwnd_ncep_interp'] = combined_df['vwnd_ncep_interp'].astype(float)\n",
    "\n",
    "# Display the updated DataFrame head\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign the interpolated uwnd and vwnd values to the combined DataFrame using the closest grid point (discrete values)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming combined_df, uwnd_3d_array, vwnd_3d_array, latitudes, and longitudes are already defined\n",
    "\n",
    "# Step 1: Get a list of the unique DOY_int values in the data frame\n",
    "unique_doy = combined_df['DOY_int'].unique()\n",
    "\n",
    "# Step 2: Iterate through each unique value\n",
    "for doy in unique_doy:\n",
    "    # Step 3: Select the corresponding layers of the 3D arrays for the same DOY\n",
    "    uwnd_layer = uwnd_3d_array[doy - 1]  # Assuming DOY starts from 1\n",
    "    vwnd_layer = vwnd_3d_array[doy - 1]  # Assuming DOY starts from 1\n",
    "    \n",
    "    # Get the buoy data for the current DOY\n",
    "    buoy_data = combined_df[combined_df['DOY_int'] == doy]\n",
    "    \n",
    "    # Step 4: Assign the discrete values from uwnd and vwnd layers to the buoy points\n",
    "    buoy_points = buoy_data[['Latitude', 'Longitude']].values\n",
    "    assigned_uwnd = []\n",
    "    assigned_vwnd = []\n",
    "    \n",
    "    for lat, lon in buoy_points:\n",
    "        # Find the closest grid point\n",
    "        lat_idx = (np.abs(latitudes - lat)).argmin()\n",
    "        lon_idx = (np.abs(longitudes - lon)).argmin()\n",
    "        \n",
    "        # Assign the discrete values\n",
    "        assigned_uwnd.append(uwnd_layer[lat_idx, lon_idx])\n",
    "        assigned_vwnd.append(vwnd_layer[lat_idx, lon_idx])\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    assigned_uwnd = np.array(assigned_uwnd)\n",
    "    assigned_vwnd = np.array(assigned_vwnd)\n",
    "    \n",
    "    # Step 5: Append the results as new columns in the dataframe\n",
    "    combined_df.loc[combined_df['DOY_int'] == doy, 'uwnd_ncep_discrete'] = assigned_uwnd\n",
    "    combined_df.loc[combined_df['DOY_int'] == doy, 'vwnd_ncep_discrete'] = assigned_vwnd\n",
    "\n",
    "# Ensure the new columns are of float type\n",
    "combined_df['uwnd_ncep_discrete'] = combined_df['uwnd_ncep_discrete'].astype(float)\n",
    "combined_df['vwnd_ncep_discrete'] = combined_df['vwnd_ncep_discrete'].astype(float)\n",
    "\n",
    "# Display the updated DataFrame head\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the combined DataFrame to a CSV file for validation\n",
    "combined_df.to_csv('../data/cleaned/buoydata/combined_buoy_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing current buoy data and forecasts for use in model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Concatenate all current buoy data into a single dataframe\n",
    "This section will collect all of the cleaned buoy data and combine them into a single dataframe. A column to represent the day of year (DOY) as an integer is also added. Finally, the buoy data is subsetted to only the most recent positions for each buoyID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BuoyID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Min</th>\n",
       "      <th>DOY</th>\n",
       "      <th>POS_DOY</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>BP</th>\n",
       "      <th>Ts</th>\n",
       "      <th>Ta</th>\n",
       "      <th>DOY_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>300234065495190</td>\n",
       "      <td>2024</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>301.6250</td>\n",
       "      <td>301.6250</td>\n",
       "      <td>70.22420</td>\n",
       "      <td>232.47340</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>-4.70</td>\n",
       "      <td>-52.6</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>300434065882720</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "      <td>301.5268</td>\n",
       "      <td>301.5268</td>\n",
       "      <td>71.43801</td>\n",
       "      <td>200.66946</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              BuoyID  Year  Hour  Min       DOY   POS_DOY  Latitude  \\\n",
       "183  300234065495190  2024    15    0  301.6250  301.6250  70.22420   \n",
       "222  300434065882720  2024    12   38  301.5268  301.5268  71.43801   \n",
       "\n",
       "     Longitude      BP    Ts    Ta  DOY_int  \n",
       "183  232.47340  1010.6 -4.70 -52.6      301  \n",
       "222  200.66946  -999.0 -0.88   NaN      301  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate multiple current buoy CSV files into a single DataFrame and add a new column with the Day of Year (DOY) as an integer\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Define the path to the folder containing the CSV files\n",
    "folder_path = '../data/cleaned/buoydata/current'\n",
    "\n",
    "# Use glob to get all CSV files in the folder\n",
    "csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through the list of CSV files and read each one into a DataFrame\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df_current = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Make a new column in the dataframe of DOY truncated to an integer\n",
    "combined_df_current['DOY_int'] = combined_df_current['DOY'].astype(int)\n",
    "\n",
    "# Rename the lat and lon columns to Latitude and Longitude\n",
    "combined_df_current.rename(columns={'Lat': 'Latitude', 'Lon': 'Longitude'}, inplace=True)\n",
    "\n",
    "# For each unique BuoyID, keep only the most current position based on the DOY column\n",
    "combined_df_current = combined_df_current.loc[combined_df_current.groupby('BuoyID')['DOY'].idxmax()]\n",
    "\n",
    "# Display the combined DataFrame\n",
    "combined_df_current.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Converting the netCDF GFS forecast data into arrays for interpolation with current buoy positions for use as initial conditions for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell converts the GFS netCDF file into arrays for the `ugrd` and `vgrd` variables at a specific pressure level (currently set to the second item in the list, which corresponds to near-surface conditions). The script ensures that there is exactly one file in the specified directory and extracts the necessary variables from the netCDF dataset. The shapes of the resulting arrays are printed to verify the extraction process. This step is crucial for preparing the forecast data for interpolation with the current buoy positions, which will be used as initial conditions for prediction models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ugrd_array shape: (1536, 3072)\n",
      "vgrd_array shape: (1536, 3072)\n"
     ]
    }
   ],
   "source": [
    "# Convert the GFS netCDF file into arrays for the ugrd and vgrd variables at a specific pressure level (currently set to the second item in the list \n",
    "# which corresponds to near surface conditions)\n",
    "\n",
    "import netCDF4 as nc\n",
    "import os\n",
    "\n",
    "# Define the directory path to the dataset in the data/raw/forecasts/gfs folder\n",
    "directory_path = '../data/raw/forecasts/gfs'\n",
    "\n",
    "# Get the list of files in the directory\n",
    "files = os.listdir(directory_path)\n",
    "\n",
    "# Ensure there is exactly one file in the directory\n",
    "if len(files) != 1:\n",
    "    raise ValueError(\"There should be exactly one file in the directory.\")\n",
    "\n",
    "# Get the file path\n",
    "file_path = os.path.join(directory_path, files[0])\n",
    "\n",
    "# Reopen the dataset\n",
    "dataset = nc.Dataset(file_path, 'r')\n",
    "\n",
    "# Extract the second item in the pfull list\n",
    "pfull_index = 1\n",
    "\n",
    "# Create arrays for ugrd and vgrd with pfull set to the second item\n",
    "ugrd_array = dataset.variables['ugrd'][0, pfull_index, :, :]\n",
    "vgrd_array = dataset.variables['vgrd'][0, pfull_index, :, :]\n",
    "\n",
    "# Print the shapes of the arrays to verify\n",
    "print(\"ugrd_array shape:\", ugrd_array.shape)\n",
    "print(\"vgrd_array shape:\", vgrd_array.shape)\n",
    "\n",
    "# Close the dataset\n",
    "dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interpolating forecast data with current buoy positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WORK FOR THIS IS ONGOING"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
