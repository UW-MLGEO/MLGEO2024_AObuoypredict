{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "\n",
    "# === Step 1: Load the data ===\n",
    "# Load the dataset containing buoy trajectory and wind data\n",
    "buoy_data = pd.read_csv('../combined_buoy_data.csv')\n",
    "\n",
    "# Keep only the necessary columns for the task\n",
    "columns_to_keep = ['Latitude', 'Longitude', 'BuoyID', 'datetime', 'era5_uwnd', 'era5_vwnd', 'displacement', 'heading']\n",
    "buoy_data = buoy_data[columns_to_keep].copy()\n",
    "\n",
    "# Convert the datetime column to a proper datetime object\n",
    "buoy_data['datetime'] = pd.to_datetime(buoy_data['datetime'])\n",
    "\n",
    "# === Step 2: Define features and targets ===\n",
    "# Features include buoy location, wind data, and metadata\n",
    "X = buoy_data[['Latitude', 'Longitude', 'era5_uwnd', 'era5_vwnd', 'BuoyID', 'datetime']]\n",
    "\n",
    "# Targets are displacement and heading (trajectory data)\n",
    "y = buoy_data[['displacement', 'heading']]\n",
    "\n",
    "# Grouping information (BuoyID) is needed for GroupKFold\n",
    "groups = buoy_data['BuoyID']\n",
    "\n",
    "# Ensure the directory for saving predictions exists\n",
    "predictions_dir = '../data/processed/predictions'\n",
    "os.makedirs(predictions_dir, exist_ok=True)\n",
    "\n",
    "# === Step 3: Set up GroupKFold for cross-validation ===\n",
    "cv_folds = 5\n",
    "group_kf = GroupKFold(n_splits=cv_folds)\n",
    "\n",
    "# === Step 4: Define deep learning architectures ===\n",
    "\n",
    "# Fully Connected Network (FCN)\n",
    "def build_fcn(input_shape):\n",
    "    \"\"\"\n",
    "    A simple fully connected network (FCN) for baseline comparisons.\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.Dense(128, activation='relu'),  # First dense layer with ReLU\n",
    "        layers.Dropout(0.2),  # Dropout for regularization\n",
    "        layers.Dense(64, activation='relu'),  # Second dense layer with ReLU\n",
    "        layers.Dense(2)  # Output layer for displacement and heading\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Recurrent Neural Network (RNN)\n",
    "def build_rnn(input_shape):\n",
    "    \"\"\"\n",
    "    An RNN using LSTM layers to capture temporal dependencies.\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.LSTM(64, return_sequences=True),  # First LSTM layer with 64 units\n",
    "        layers.LSTM(32),  # Second LSTM layer with 32 units\n",
    "        layers.Dense(2)  # Output layer for displacement and heading\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Convolutional Neural Network (CNN)\n",
    "def build_cnn(input_shape):\n",
    "    \"\"\"\n",
    "    A CNN to capture spatial relationships in the data.\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.Conv1D(32, kernel_size=3, activation='relu'),  # First convolutional layer\n",
    "        layers.Conv1D(64, kernel_size=3, activation='relu'),  # Second convolutional layer\n",
    "        layers.GlobalAveragePooling1D(),  # Pooling to reduce dimensionality\n",
    "        layers.Dense(64, activation='relu'),  # Dense layer with ReLU\n",
    "        layers.Dense(2)  # Output layer for displacement and heading\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# === Step 5: Define the physics-informed loss function ===\n",
    "def physics_informed_loss(y_true, y_pred, wind_u, wind_v, lambda1=1.0, lambda2=0.1):\n",
    "    \"\"\"\n",
    "    Combines traditional MSE loss with a physics-informed constraint.\n",
    "    \"\"\"\n",
    "    # Mean Squared Error (MSE) loss for trajectory predictions\n",
    "    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    \n",
    "    # Constraint: Predicted displacement should align with wind data\n",
    "    physical_constraint = tf.reduce_mean(tf.square(y_pred - (wind_u + wind_v)))\n",
    "    \n",
    "    # Combined loss\n",
    "    return lambda1 * mse_loss + lambda2 * physical_constraint\n",
    "\n",
    "# === Step 6: Train and evaluate models ===\n",
    "results = []  # Store results for comparison\n",
    "architectures = {'FCN': build_fcn, 'RNN': build_rnn, 'CNN': build_cnn}  # Model architectures\n",
    "\n",
    "for arch_name, build_model in architectures.items():\n",
    "    print(f\"\\nTesting architecture: {arch_name}\")\n",
    "    model_scores = []  # RMSE for each fold\n",
    "    fold_times = []  # Time taken for each fold\n",
    "\n",
    "    for fold_num, (train_idx, val_idx) in enumerate(group_kf.split(X, y, groups=groups)):\n",
    "        print(f\"\\nFold {fold_num + 1}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        # === Prepare train and validation data ===\n",
    "        # Separate training and validation data\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        # Extract wind data for physics-informed loss\n",
    "        wind_u_train, wind_v_train = X_train['era5_uwnd'], X_train['era5_vwnd']\n",
    "        wind_u_val, wind_v_val = X_val['era5_uwnd'], X_val['era5_vwnd']\n",
    "\n",
    "        # Drop non-numerical features for training\n",
    "        X_train = X_train.drop(columns=['BuoyID', 'datetime'])\n",
    "        X_val = X_val.drop(columns=['BuoyID', 'datetime'])\n",
    "\n",
    "        # === Build and compile the model ===\n",
    "        model = build_model(input_shape=(X_train.shape[1],))\n",
    "        model.compile(\n",
    "            optimizer=optimizers.Adam(learning_rate=0.001),  # Adam optimizer\n",
    "            loss=lambda y_true, y_pred: physics_informed_loss(y_true, y_pred, wind_u_train, wind_v_train),  # Custom loss\n",
    "            metrics=['mse']  # Mean squared error as a metric\n",
    "        )\n",
    "\n",
    "        # === Train the model ===\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=50,  # Maximum 50 epochs\n",
    "            batch_size=32,  # Mini-batch size\n",
    "            verbose=1,\n",
    "            callbacks=[callbacks.EarlyStopping(patience=5, restore_best_weights=True)]  # Stop early if no improvement\n",
    "        )\n",
    "\n",
    "        # === Evaluate the model ===\n",
    "        y_pred = model.predict(X_val)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))  # Root mean squared error\n",
    "        model_scores.append(rmse)\n",
    "        print(f\"Fold {fold_num + 1} RMSE: {rmse:.3f}\")\n",
    "\n",
    "        # Record fold time\n",
    "        fold_time = time.time() - start_time\n",
    "        fold_times.append(fold_time)\n",
    "        print(f\"Fold {fold_num + 1} time: {fold_time:.2f} seconds\")\n",
    "\n",
    "        # === Save predictions for analysis ===\n",
    "        predictions_df = pd.DataFrame({\n",
    "            'BuoyID': X.iloc[val_idx]['BuoyID'].values,\n",
    "            'True displacement': y_val['displacement'].values,\n",
    "            'True heading': y_val['heading'].values,\n",
    "            'Predicted displacement': y_pred[:, 0],\n",
    "            'Predicted heading': y_pred[:, 1]\n",
    "        })\n",
    "        predictions_file = os.path.join(predictions_dir, f\"{arch_name}_fold{fold_num + 1}_predictions.csv\")\n",
    "        predictions_df.to_csv(predictions_file, index=False)\n",
    "\n",
    "    # === Record results for this architecture ===\n",
    "    mean_rmse = np.mean(model_scores)  # Average RMSE\n",
    "    std_rmse = np.std(model_scores)  # Standard deviation of RMSE\n",
    "    total_time = sum(fold_times)  # Total time for training and evaluation\n",
    "\n",
    "    results.append({\n",
    "        'Model': arch_name,\n",
    "        'Mean RMSE': mean_rmse,\n",
    "        'RMSE StdDev': std_rmse,\n",
    "        'Total Time (s)': total_time,\n",
    "        'Mean Time per Fold (s)': np.mean(fold_times)\n",
    "    })\n",
    "\n",
    "    print(f\"\\nCompleted cross-validation for {arch_name}. \"\n",
    "          f\"Mean RMSE: {mean_rmse:.3f}, Std. Dev: {std_rmse:.3f}, Total Time: {total_time:.2f} seconds\")\n",
    "\n",
    "# === Save and summarize results ===\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('model_comparison_results.csv', index=False)\n",
    "\n",
    "# Identify the best model based on Mean RMSE\n",
    "best_model_row = results_df.loc[results_df['Mean RMSE'].idxmin()]\n",
    "print(f\"\\n=== Best model selected: {best_model_row['Model']} ===\")\n",
    "print(f\"Mean RMSE: {best_model_row['Mean RMSE']:.3f}, Total Time: {best_model_row['Total Time (s)']:.2f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
